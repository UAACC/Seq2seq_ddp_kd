
  0%|                                                                                                                                              | 0/12753 [00:00<?, ?it/s]
09/01/2024 15:20:20 - INFO - __main__ - ***** Running training *****
09/01/2024 15:20:20 - INFO - __main__ -   Num examples = 204045
09/01/2024 15:20:20 - INFO - __main__ -   Num Epochs = 1
09/01/2024 15:20:20 - INFO - __main__ -   Instantaneous batch size per device = 4
09/01/2024 15:20:20 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16
09/01/2024 15:20:20 - INFO - __main__ -   Gradient Accumulation steps = 1
09/01/2024 15:20:20 - INFO - __main__ -   Total optimization steps = 12753.0
LLM Loss: 3.6843008995056152
Pad Token ID: 0
Labels: tensor([    3, 18540,  2487,   969,    29,    65,  8151,     8,   166,  7155,
            7, 31430,    13,   112, 16117,  2843,    38,  1401,    13,   112,
         5220,     7, 12191,    12,  2902,   581,     8,   789,    31,     7,
          126,  1456,  2219,     5,     1,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,    94,    19,     3,     9,  8899,  5016,
           24,  3200,   544,  1163,    31,     7,  7353,  6123,  4889,    11,
           80,    13,     8,   296,    31,     7,  1374, 11441,    21,     8,
         1058,    13,  1580,  1124,     5,     1,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,    37,  2384,
          636,    41, 13336,    61,   871,    33,   271, 16524,    15,    26,
           21,  6585,  1041,    16,     3,     9,  7358,   147,   613,  8467,
           11,     8, 12493,    13,  3518,  6036,     5,     1,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,    71,  1268, 12039,    49,    65,  1869,   160,   804,
          239,    44,     8,  6885,   255,    65,  1279,    16,    21,     8,
          336,  9455,   203,     5,     1,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
         -100,  -100,  -100,  -100,  -100,  -100], device='cuda:0')
Cross-Entropy Loss: 3.6843008995056152
teacher logits size torch.Size([4, 104, 32128])
teacher logits size torch.Size([416, 32128])
KL Divergence Loss: nan
loss is nan